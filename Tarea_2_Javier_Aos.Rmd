---
title: 'Tarea 2: Series temporales y aprendizaje no supervisado'
author: "Javier Aos"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
setwd('G:/My Drive/1.3 Master/Modules/08_Data_mining/TareaII')
pacman::p_load(readxl, fpp2, tseries, forescast, ggplot2, seasonal, decomposer, TSA)
```

# Parte 1: Series temporales

## Presentación de la serie a analizar

En esta ocasión vamos a analizar una serie temporal del producto interior bruto (PIB) mundial obtenida de "U.S. Energy Information Administration Data". Contamos con datos mensuales desde el año 2000 hasta el 2021 incluidos.

```{r}
df <- read.csv(
  'G:/My Drive/1.3 Master/Modules/08_Data_mining/TareaII/EIA-STEO_RGDPQ_WORLD_M.csv',
  sep = ",")
df <- df[order(as.numeric(rownames(df)), decreasing = TRUE),,drop=FALSE]
gdp_ts <- ts(df$Value, start=c(2000,1), frequency = 12)
```

## Representación gráfica y descomposición estacional

```{r}
plot.ts(gdp_ts)
gdp_desc <- decompose(gdp_ts, type = 'additive')
plot(gdp_desc)
```

Podemos ver que la serie presenta una tendencia ascendente lineal con ciertas recesiones en algunos periodos. A priori no hay comportamiento estacional lo cual va a dificultar la predicción.

## Contraste de normalidad de los residuos

```{r}
ks.test(gdp_desc$random,'pnorm')
shapiro.test(gdp_desc$random)
```

Vemos que los residuos no pasan los tests de normalidad.

## Tratamiento de la serie

### Eliminar la heterocedasticidad. Estabilización de la varianza.

```{r}
gdplog <- log(gdp_ts)
```

#### Eliminar tendencia

```{r}
# Eliminar tendencia
gdp.diff_1<-diff(gdplog)
```

### Comprobación y corrección de la estacionalidad (Correlogramas)

```{r fig.width=5, fig.height=2}
library(forecast)
#Calculamos  las autocorrelaciones simples hasta el retardo 48
ggAcf(gdp_ts, lag=48) # Decrecimineto lento--> No estacionaria-->diferenciar
#Calculamos  las autocorrelaciones parciales hasta el retardo 48
ggPacf(gdp_ts, lag=48)
```

Vemos que la serie no es estacionaria, por lo tanto, la diferenciamos.

```{r}
gdp.diff_1_12<-diff(gdp.diff_1, lag = 12)
```

```{r}
## Contraste de normalidad de los residuos
ks.test(gdp.diff_1_12,'pnorm')
shapiro.test(gdp.diff_1_12)
```

Sigue sin pasar los tests de normalidad.

## Ventanas de ajuste y evaluación 

```{r}
gdp_tr<-window(x = gdp_ts, end = c(2020,12))
gdp_tst<-window(x = gdp_ts, start = c(2021,1))
```

## Modelos de suavizado exponencial

### Suavizado exponencial simple con predicción a un año

```{r, results='hide'}
gdp_s1=ses(gdp_tr, h=12)
```

### Suavizado Exponencial doble de Holt 

```{r, results='hide'}
gdp_sh <- holt(gdp_tr, h=12)
```

### Ajuste de modelo

```{r, results='hide'}
gdp_hw_add <- hw(gdp_tr, h=12,level = c(80, 95))
gdp_hw_mul <- hw(gdp_tr, h=12, seasonal="multiplicative",level = c(80, 95))
```

### Predicciones utilizando ETS

```{r}
ETS_pred<-forecast(gdp_tr,h=12)
```

## Modelos ARIMA

### Ajuste con la función auto.arima

```{r, results='hide'}
fitgdp <- auto.arima(gdp_tr,seasonal=TRUE)
pred <- forecast(fitgdp, h=12)
```

### Ajuste manual de ARIMA

```{r}
fitgdp_manual <- gdp_tr %>%  Arima(order=c(1,1,1), seasonal=c(0,0,1))
pred_manual <- forecast(fitgdp_manual, h=12)
```

## Se prueba la precisión de las distintas predicciones de los modelos

```{r}
accuracy(gdp_s1,gdp_tst)
accuracy(gdp_sh,gdp_tst)
accuracy(gdp_hw_add,gdp_tst)
accuracy(gdp_hw_mul,gdp_tst)
accuracy(ETS_pred,gdp_tst)
accuracy(pred,gdp_tst)
accuracy(pred_manual,gdp_tst)
```

Vemos que la predicción que más se ajusta a los datos test es la del método Holt's (gdp_sh). Por lo tanto lo seleccionamos y ajustamos a los datos totales.

## Representación de la predicción del mejor modelo (Doble Holt)

```{r fig.width=5, fig.height=2}
#Representamos los valores observados y los suavizados con la predicción 
autoplot(gdp_sh) +
  autolayer(fitted(gdp_sh), series="Fitted") +autolayer(gdp_tst, series="actual") +
  ylab("GDP") + xlab("Mes/Año")
```

## Ajuste del modelo final a los datos completos y predicción

```{r fig.width=5, fig.height=2.5}
###  Suavizado Exponencial doble de Holt 
gdp_sh_total <- holt(gdp_ts, h=12)
# Inspección del objeto creado y Distribución de residuos
print(gdp_sh_total)
gdp_sh_total$model
autoplot(gdp_sh_total$residuals)
```

## Representación gráfica de la predicción

```{r fig.width=5, fig.height=2}
autoplot(gdp_sh_total)+ autolayer(fitted(gdp_sh_total), series="Fitted") +
  ylab("GDP") + xlab("Year")
```

## Test de Ljung-Box

```{r}
forecast::checkresiduals(gdp_sh_total)
```

A pesar de ser el mejor modelo no pasa el test de Ljung-Box de residuos incorrelados.

## Conclusiones primera parte

Parece que ninguno de los modelos es los bastante adecuado como para poder sacar conclusiones y predicciones acertadas. Además, como hemos visto, el mejor modelo no pasa el test de Ljung-Box de residuos incorrelados, por lo que las predicciónes que hagamos no serán precisas. Aún así, con el objetivo de sacar una conclusión final de esta práctica, siguiendo la tendencia y la predicción del suavizado exponencial doble Holt, podemos concluir que el PIB mundial seguirá su tendencia creciente en 2022.


# Parte 2: Técnicas no supervisadas

```{r include=FALSE, results='hide'}
setwd("G:/My Drive/1.3 Master/Modules/08_Data_mining/TareaII")
source("G:/My Drive/1.3 Master/Modules/08_Data_mining/Funciones_R.R")
paquetes(c("qgraph","devtools", "FactoMineR", "RcmdrMisc","GPArotation"))
source("G:/My Drive/1.3 Master/Modules/08_Data_mining/Funciones_Clust.R")
paquetes(c("factoextra","cluster","fpc", "clValid"))
```

```{r warning=FALSE, include=FALSE, results='hide'}
library(devtools)
install_github("vqv/ggbiplot")
library(ggbiplot)
```

## Lectura y depuración del dataset

```{r message=FALSE, warning=FALSE, results='hide'}
elec <- readxl::read_excel(
  "G:/My Drive/1.3 Master/Modules/08_Data_mining/Datos/DatosEleccionesEspaña.xlsx")
```

```{r warning=FALSE, results='hide'}
# Ciudades con más de 100000 habitantes
elec_r2<-na.omit(elec[elec$Population >100000 & elec$Population <500000,])

# Selecciono las numéricas
elec_r<-Filter(is.numeric, elec_r2)[,-1] # Elimino Código de provincia
rownames(elec_r)<-elec_r2$Name
names(elec_r[-c(1,2,32)])
names(elec_r)<-c(
  "Pop", "Cens", "Abs", "AbsA" , "Izda",   "Dcha",   "Otr",  "IzqA",  "DechA",   
"Age4",    "Age19","Age19_65",  "Age65",  "WomP", "Forei", "SameCom","SCDifProv",  "DifCom",
 "UnL25", "Un25_40" , "UnM40" , "AgrU" , "IndU"   ,  "ConsU", "ServU"  ,   "Empr",   "Indus", 
"Const",    "ComHost" , "Servi", "inmuebles",  "Pob2010",    "SUPERFICIE",   
"PobChange",   "PersInm","Explot" )

# Elimino las variables de población y dicótomas
elec_r<-elec_r[,-c(1,2,4,8,9,32)]
```

## Seleccionamos las 10 variables con mayor MSA

```{r}
# Eliminamos las variables que producen un error de colinealidad
x<-psych::KMO(elec_r[,c(5:12,22:29)])
sort(x$MSAi, decreasing = TRUE)
```

```{r warning=FALSE}
# Seleccionamos las 10 variables con un MSA más alto
elec_r<-elec_r[,c(
  'WomP','Age4','Const','Indus','inmuebles','PobChange','PersInm','ComHost',
  'Servi','SCDifProv')]
elec_r$CCAA<-elec_r2$CCAA
rownames(elec_r)<-elec_r2$Name
```

## Agregamos valores por CCAA

```{r warning=FALSE}
ccaa<-aggregate(.~CCAA,elec_r,mean)
rownames(ccaa)<-ccaa$CCAA
ccaa<-ccaa[,-1]
```

## Escalamos datos ya que hay distintas unidades de medida

```{r warning=FALSE}
ccaa.sc<-scale(ccaa)
```

## Exploramos clustering jerárquico con distintos Linkages

```{r warning=FALSE, fig.width=5, fig.height=3}
methods<-c("complete","average",'ward.D2')
hclist<-list()
val.hc<-c()
for (i in 1:length(methods)){
  hc=hclust(dist(ccaa.sc),method =methods[i])
  hclist[[i]]<-hc
 print(fviz_dend(hc,k = 4, cex = 0.5, color_labels_by_k = T, rect = T)+
         ggtitle(paste('Linkage ', methods[i])))
 #Validación interna
 cl<-cutree(hc, k = 4) 
 md.val<-medidasVal(ccaa.sc,cl,cl,methods[i])
 
 # Generar vector de medidas de validación
 val.hc<- rbind(val.hc,md.val)
}

names(hclist) <- rownames(val.hc)<-methods
```

## Exploramos k-means con 4 grupos

```{r warning=FALSE, fig.width=6, fig.height=3.3}
km.out=kmeans(ccaa.sc,4)
fviz_cluster(km.out, data = ccaa.sc,  ellipse.type = "convex", palette = "jco",repel = TRUE,
             ggtheme = theme_minimal())
```

## Intentamos unir fuerzas con método híbrido (hkmeans)

```{r warning=FALSE, fig.width=6, fig.height=3}
hk.out=hkmeans(ccaa.sc,4)

hkmeans_tree(hk.out, cex = 0.6)
fviz_cluster(hk.out, data = ccaa.sc,  ellipse.type = "convex", palette = "jco",repel = TRUE,
             ggtheme = theme_minimal())
```

### Medidas de validación

```{r warning=FALSE}
md.km<-medidasVal(ccaa.sc,km.out$cluster,km.out$cluster,'kmeans')
md.hk<-medidasVal(ccaa.sc,hk.out$cluster,hk.out$cluster,'hkmeans') ## Son iguales

ValT<-rbind(val.hc,md.km,md.hk) ## El mismo clustering con varias técnicas
ValT
```

Average, ward.D2 y md.hk tiene exactamente el mismo silhouette y wss.

## Para una mejor interpretabilidad hacemos una reducción por componentes principales 

```{r warning=FALSE}
pr.out=prcomp(ccaa.sc, scale. = T)
# Varianza explicada
summary(pr.out)$importance[3,2]
```

Con la reducción por componenetes principales conseguimos explicar un 77.31% de la varianza.

```{r warning=FALSE}
# Biplot en plano de componentes
ggbiplot::ggbiplot(pr.out,labels=rownames(ccaa),
                   ellipse = TRUE, circle = TRUE)
```

Vemos que el PC1 tiene mucha carga de variables como Indust, Const, ComHost, Servi o Inmuebles. Por lo tanto en el eje horizontal se están clasificando las CCAA según su infraestructura/desarrollo industrial en el momento de la medición (parte izquierda) frente a el no desarrollo industrial (parte derecha). Vemos que por ejemplo, Baleares es un CA con mucho peso industrial, cantidad de inmuebles, hostelería, servicios, construcción etc. Por lo tanto, vemos que podría ser una CA que todavía tiene capacidad de crecimiento en su construcción. En cambio vemos a Madrid situada en la parte derecha, ya que es una CA con mucho desarrollo, quedando "poco espacio" para la construcción de por ejemplo nuevos inmuebles, comercios de hostelería, servicios etc. es decir, es una CA con infraestructura ya establecida.

Si nos fijamos en el PC2 vemos que tiene una gran influecia de variables como Age4, PobChange o PersInm, pudiendo interpretasarse como una natalidad y cambio poblacional alto, frente a la parte de abajo que representa la presencia de gente más mayor y una natalidad más baja con variables como WomP (muy relacionada con gente de edad avanzada debido a la esperanza de vida de las mujeres) o SCDifProv. Vemos ciudad como Cantabria o Casatilla y León con más población mayor, frente a Madrid que presenta una mayor natalidad y cambio poblacional.

## Ajustamos el cluster jerárquico a la solución de dos componentes

```{r warning=FALSE}
hc.pr=hclust(dist(pr.out$x[ ,1:2]))
fviz_dend(hc.pr,k = 4, cex = 0.5, color_labels_by_k = T, rect = T)+
  ggtitle("Cluster Jerárquico 2 PC")
cl.hc.pr<-cutree(hc.pr, k = 4) 

km.out.pr=kmeans(pr.out$x[ ,1:2],4)
fviz_cluster(km.out, data = pr.out$x[ ,1:2], 
             ggtheme = theme_minimal())
km.out.pr$centers
```

### Medidas de validación

```{r warning=FALSE}
md.km<-medidasVal(pr.out$x[ ,1:2],km.out.pr$cluster,km.out.pr$cluster,'kmeans PCA')
md.hk<-medidasVal(pr.out$x[ ,1:2],cl.hc.pr,cl.hc.pr,'hclus PCA') 

ValT<-rbind(md.km,md.hk) ## Un poco mejor el k means
ValT
```

Md.hk funciona algo mejor, aunque no hay mucha diferencia.

## Conclusión segunda parte

En conclusión, vemos que el cluester kmedias ha agrupado 4 grupos teniendo el verde (arriba derecha) representado por CCAA con un desarrollo de la insutria y construcción bien establecido y una alta natalidad y cambio poblacional, encontrado CCAA como Madrid o Cataluña. En el grupo rojo (centro) vemos CCAA que se acercan al centro y por tanto serían "neutras" no destacando en ninguna de las variables. En el grupo morado (abajo derecha) vemos CCAA con una buena infraestructura pero una población predominante envejecida, encontrado algunas Cantabria o Castilla y León. Por último en el grupo azul (izquierda) vemos CCAA que aún tienen una gran capacidad de mejora en su infraestructura como baleares o Murcia.



















